{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c6730f-5d76-450b-9788-ec883d024f57",
   "metadata": {},
   "source": [
    "# Hugging Face Transformers 微调训练入门\n",
    "\n",
    "本示例将介绍基于 Transformers 实现模型微调训练的主要流程，包括：\n",
    "- 数据集下载\n",
    "- 数据预处理\n",
    "- 训练超参数配置\n",
    "- 训练评估指标设置\n",
    "- 训练器基本介绍\n",
    "- 实战训练\n",
    "- 模型保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0b1e12-1921-4438-8d5d-9760a629dcfe",
   "metadata": {},
   "source": [
    "## YelpReviewFull 数据集\n",
    "\n",
    "**Hugging Face 数据集：[ YelpReviewFull ](https://huggingface.co/datasets/yelp_review_full)**\n",
    "\n",
    "### 数据集摘要\n",
    "\n",
    "Yelp评论数据集包括来自Yelp的评论。它是从Yelp Dataset Challenge 2015数据中提取的。\n",
    "\n",
    "### 支持的任务和排行榜\n",
    "文本分类、情感分类：该数据集主要用于文本分类：给定文本，预测情感。\n",
    "\n",
    "### 语言\n",
    "这些评论主要以英语编写。\n",
    "\n",
    "### 数据集结构\n",
    "\n",
    "#### 数据实例\n",
    "一个典型的数据点包括文本和相应的标签。\n",
    "\n",
    "来自YelpReviewFull测试集的示例如下：\n",
    "\n",
    "```json\n",
    "{\n",
    "    'label': 0,\n",
    "    'text': 'I got \\'new\\' tires from them and within two weeks got a flat. I took my car to a local mechanic to see if i could get the hole patched, but they said the reason I had a flat was because the previous patch had blown - WAIT, WHAT? I just got the tire and never needed to have it patched? This was supposed to be a new tire. \\\\nI took the tire over to Flynn\\'s and they told me that someone punctured my tire, then tried to patch it. So there are resentful tire slashers? I find that very unlikely. After arguing with the guy and telling him that his logic was far fetched he said he\\'d give me a new tire \\\\\"this time\\\\\". \\\\nI will never go back to Flynn\\'s b/c of the way this guy treated me and the simple fact that they gave me a used tire!'\n",
    "}\n",
    "```\n",
    "\n",
    "#### 数据字段\n",
    "\n",
    "- 'text': 评论文本使用双引号（\"）转义，任何内部双引号都通过2个双引号（\"\"）转义。换行符使用反斜杠后跟一个 \"n\" 字符转义，即 \"\\n\"。\n",
    "- 'label': 对应于评论的分数（介于1和5之间）。\n",
    "\n",
    "#### 数据拆分\n",
    "\n",
    "Yelp评论完整星级数据集是通过随机选取每个1到5星评论的130,000个训练样本和10,000个测试样本构建的。总共有650,000个训练样本和50,000个测试样本。\n",
    "\n",
    "## 下载数据集"
   ]
  },
  {
   "cell_type": "code",
   "id": "bbf72d6c-7ea5-4ee1-969a-c5060b9cb2d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:38:00.284372Z",
     "start_time": "2024-08-30T09:37:47.644596Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "dataset"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 650000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "6dc45997-e391-456f-b0b9-d3193b0f6a9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:38:00.346545Z",
     "start_time": "2024-08-30T09:38:00.344624Z"
    }
   },
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from IPython.display import display, HTML"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "9e2ecebb-d5d1-456d-967c-842a79fdd622",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:38:00.458582Z",
     "start_time": "2024-08-30T09:38:00.456141Z"
    }
   },
   "source": [
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset) - 1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset) - 1)\n",
    "        picks.append(pick)\n",
    "\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "1af560b6-7d21-499e-9b82-114be371a98a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:38:00.534003Z",
     "start_time": "2024-08-30T09:38:00.521564Z"
    }
   },
   "source": [
    "show_random_elements(dataset[\"train\"])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 star</td>\n",
       "      <td>Nice ambiance but pasta was dry and cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 star</td>\n",
       "      <td>This review is for a lunch seating. \\n\\nWe sat down, ordered, ate and nothing came back up. That's about the only nice thing I can say about the food. \\n\\nService was very friendly and it's got decent ambience, especially on the patio. \\n\\nIf you must eat here, unless you enjoy government cheese melted onto soggy cardboard, I suggest you avoid the pizzas.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5 stars</td>\n",
       "      <td>I just bought there honey at Costco, and it's delicious! I love the flavor of it, especially on plain yogurt. I will definitely purchase again. Thanks  Crockett Honey!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 stars</td>\n",
       "      <td>I recently went from mild vegetarian to full on vegan. I cook a lot at home because its not easy finding restaurants to eat at, especially in Las Vegas, the steakhouse capital of the world. I decided I needed to get out for Valentine's Day and chose to go Indian. I came across Tamba's amazing website and easily made up my mind. After making the reservation I read a few revues on Google and they worried me a bit, but I wasn't going to be shaken. I'm so glad I stayed with it, I loved this place. Staff was very friendly and the food was delicious! We tried the Bhel Puri for an appetizer, based off of the waiters recommendation, great choice. Then for entrees we went with the Aloo Gobi &amp; Chana Masala. Both were amazing and complimented each other nicely, great for sharing. She went with a glass of house Chard, which turned out to be Mondavi(Nice!) and I tried one of the many Indian Imported beers. Hayward 5000 was the beer I went with and was perfect. Gotta find that at Lee's Discount Liquor, hope they have it. \\n\\nOne side note, when they ask you for bread, it's not included. That was awkward. Also, parking is a bit rough.\\n\\nOver all this was probably one of the least expensive Vday dinners I've ever had and also one of the most satisfying.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 star</td>\n",
       "      <td>Run of the mill cheap Chinese fast food and other poor quality fast food grade food.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2 star</td>\n",
       "      <td>I was really disappointed by my experience at craftsteak.  Ate here with 5 of my dearest oldest friends for my bachelorette weekend.  Huge fan of top chef, and when I discovered tom collichio owned this place I just had to try it for our big saturday night meal.  We are all big foodies.  And no, I was not wearing a veil and tiara or any blinking jewelry.  We are all in our late 20s early 30s and were well behaved, at least til the end of the night when we had consumed several martinis and bottles of vino.  We may have been laughing loudly but we never got rowdy...and we were practically in a PDR for chrissake so I could've mooned the table next to me and only about a dozen or so people might see.  Not that I would.  Just sayin, we were hidden away.  All that being said...service was freaking awful.  Our server was an older gentleman, and he was downright rude.  If 18% gratuity had not been tacked on, I honestly might have gone 15% (which I NEVER do being a former server and bartender myself..I have maybe done this once in my life!).  I ordered the surf &amp; turf - a splurge - but usually one of my favorite things to eat.   The filet was a tad undercooked for medium rare, but I kinda like it in between rare and med rare so it was fine by me.  One of my friends couldn't handle it!  The lobster was so rubbery and chewy and coldish and flavorless...did it come out of the fridge?   Side dishes bored me (and everyone).    My opening salad was good - but only because we shared a ton of starters and I mixed the mozzarella salad with the tomato salad to make my own caprese.  I think one of my friends enjoyed her short ribs.  Nobody raved about anything.  Except maybe the hot sticky buns that come out in the beginning.  Truly sad we did not enjoy it!  Should've eaten elsewhere.  Will not return.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5 stars</td>\n",
       "      <td>I had my Bar Mitzvah here, and the event was great. The whitewater rafting is fun for all ages, and we've gone back several times. There are plenty of other things to do, such as rock climbing, a ropes course, and a plethora of other activities. Food has gotten better; the restaurant is okay. Overall, it's a must for visiting the area.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4 stars</td>\n",
       "      <td>Authentic Asian food.   Not the greasy, glazed over Chinese food that most Asian restaurants here in PHX serve.   These dishes are homemade and authentic and are really, really good.  \\n\\nBeef and broccoli is just how my mom makes it.  The green curry noodles are a delicate dish to make and can often times be watery if you don't know what you're doing.  This was done very, very well.  \\n\\nOne of the best places for Asian in PHX.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2 star</td>\n",
       "      <td>Marinelli's is a nice looking restaurant, but our meal was mediocre and the staff was inattentive, at a time when the restaurant wasn't even busy.   \\n\\nI started with the Pear and Blue Cheese salad.  It was the only part of the meal that was ok.  \\n\\nThe salad was followed by the Ricotta Gnocchi Alla Piemontese and the Chicken Al Mattone - both of which were recommended by the server.  Though the gnocchi itself was pretty good, the ragu was very salty.  Also the broth that surrounded the chicken and drench the escarole was extremely salty and difficult to eat.  \\n\\nWe also ordered a side of jumbo asparagus.  Unfortunately, it finally arrived at the moment we finished our entrees, so we asked the server to take it back.\\n\\nUnfortunately, I won't be back.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2 star</td>\n",
       "      <td>Over-hyped. Did they hand out some pills that I missed? I feel like I watched a different show than the other reviewers. Not worth enduring the time share presentation we attended to get free tickets. The two illusions were interesting, a very short reprieve from the rest of the cutesy antics.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "c9df7cd0-23cd-458f-b2b5-f025c3b9fe62",
   "metadata": {},
   "source": [
    "## 预处理数据\n",
    "\n",
    "下载数据集到本地后，使用 Tokenizer 来处理文本，对于长度不等的输入数据，可以使用填充（padding）和截断（truncation）策略来处理。\n",
    "\n",
    "Datasets 的 `map` 方法，支持一次性在整个数据集上应用预处理函数。\n",
    "\n",
    "下面使用填充到最大长度的策略，处理整个数据集："
   ]
  },
  {
   "cell_type": "code",
   "id": "8bf2b342-e1dd-4ab6-ad57-28eb2513ae38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:42:43.174317Z",
     "start_time": "2024-08-30T09:42:42.850230Z"
    }
   },
   "source": [
    "modal_name = \"google-bert/bert-large-uncased\"\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(modal_name)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:43:55.166066Z",
     "start_time": "2024-08-30T09:43:54.832584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = dataset[\"train\"][\"text\"][0]\n",
    "print(text)\n",
    "token = tokenizer.tokenize(text)\n",
    "print(token)\n",
    "tokenizer.encode_plus(text)"
   ],
   "id": "6691f4883161f69c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\n",
      "['dr', '.', 'goldberg', 'offers', 'everything', 'i', 'look', 'for', 'in', 'a', 'general', 'practitioner', '.', 'he', \"'\", 's', 'nice', 'and', 'easy', 'to', 'talk', 'to', 'without', 'being', 'patron', '##izing', ';', 'he', \"'\", 's', 'always', 'on', 'time', 'in', 'seeing', 'his', 'patients', ';', 'he', \"'\", 's', 'affiliated', 'with', 'a', 'top', '-', 'notch', 'hospital', '(', 'nyu', ')', 'which', 'my', 'parents', 'have', 'explained', 'to', 'me', 'is', 'very', 'important', 'in', 'case', 'something', 'happens', 'and', 'you', 'need', 'surgery', ';', 'and', 'you', 'can', 'get', 'refer', '##ral', '##s', 'to', 'see', 'specialists', 'without', 'having', 'to', 'see', 'him', 'first', '.', 'really', ',', 'what', 'more', 'do', 'you', 'need', '?', 'i', \"'\", 'm', 'sitting', 'here', 'trying', 'to', 'think', 'of', 'any', 'complaints', 'i', 'have', 'about', 'him', ',', 'but', 'i', \"'\", 'm', 'really', 'drawing', 'a', 'blank', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2852, 1012, 18522, 4107, 2673, 1045, 2298, 2005, 1999, 1037, 2236, 18742, 1012, 2002, 1005, 1055, 3835, 1998, 3733, 2000, 2831, 2000, 2302, 2108, 9161, 6026, 1025, 2002, 1005, 1055, 2467, 2006, 2051, 1999, 3773, 2010, 5022, 1025, 2002, 1005, 1055, 6989, 2007, 1037, 2327, 1011, 18624, 2902, 1006, 27935, 1007, 2029, 2026, 3008, 2031, 4541, 2000, 2033, 2003, 2200, 2590, 1999, 2553, 2242, 6433, 1998, 2017, 2342, 5970, 1025, 1998, 2017, 2064, 2131, 6523, 7941, 2015, 2000, 2156, 15744, 2302, 2383, 2000, 2156, 2032, 2034, 1012, 2428, 1010, 2054, 2062, 2079, 2017, 2342, 1029, 1045, 1005, 1049, 3564, 2182, 2667, 2000, 2228, 1997, 2151, 10821, 1045, 2031, 2055, 2032, 1010, 2021, 1045, 1005, 1049, 2428, 5059, 1037, 8744, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=600)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ],
   "id": "5c08ab2d7c2759e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "47a415a8-cd15-4a8c-851b-9b4740ef8271",
   "metadata": {},
   "source": [
    "show_random_elements(tokenized_datasets[\"train\"], num_examples=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1c33d153-f729-4f04-972c-a764c1cbbb8b",
   "metadata": {},
   "source": [
    "### 数据抽样\n",
    "\n",
    "使用 1000 个数据样本，在 BERT 上演示小规模训练（基于 Pytorch Trainer）\n",
    "\n",
    "`shuffle()`函数会随机重新排列列的值。如果您希望对用于洗牌数据集的算法有更多控制，可以在此函数中指定generator参数来使用不同的numpy.random.Generator。"
   ]
  },
  {
   "cell_type": "code",
   "id": "a17317d8-3c6a-467f-843d-87491f600db1",
   "metadata": {},
   "source": [
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42)\n",
    "eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d3b65d63-2d3a-4a56-bc31-6e88a29e9dec",
   "metadata": {},
   "source": [
    "## 微调训练配置\n",
    "\n",
    "### 加载 BERT 模型\n",
    "\n",
    "警告通知我们正在丢弃一些权重（`vocab_transform` 和 `vocab_layer_norm` 层），并随机初始化其他一些权重（`pre_classifier` 和 `classifier` 层）。在微调模型情况下是绝对正常的，因为我们正在删除用于预训练模型的掩码语言建模任务的头部，并用一个新的头部替换它，对于这个新头部，我们没有预训练的权重，所以库会警告我们在用它进行推理之前应该对这个模型进行微调，而这正是我们要做的事情。"
   ]
  },
  {
   "cell_type": "code",
   "id": "4d2af4df-abd4-4a4b-94b6-b0e7375304ed",
   "metadata": {},
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(modal_name, num_labels=5)\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b44014df-b52c-4c72-9e9f-54424725a473",
   "metadata": {},
   "source": [
    "### 训练超参数（TrainingArguments）\n",
    "\n",
    "完整配置参数与默认值：https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/trainer#transformers.TrainingArguments\n",
    "\n",
    "源代码定义：https://github.com/huggingface/transformers/blob/v4.36.1/src/transformers/training_args.py#L161\n",
    "\n",
    "**最重要配置：模型权重保存路径(output_dir)**"
   ]
  },
  {
   "cell_type": "code",
   "id": "98c01d5c-de72-4ff0-b11d-e07ac5346888",
   "metadata": {},
   "source": [
    "model_dir = \"models/gpt2-finetune-yelp\"\n",
    "\n",
    "# logging_steps 默认值为500，根据我们的训练数据和步长，将其设置为100\n",
    "from transformers import TrainingArguments\n",
    "num_epochs = 2\n",
    "batch_size = 15\n",
    "warmup_steps = int(0.1 * (len(train_dataset) * num_epochs // batch_size))  # 10% of total steps\n",
    "\n",
    "training_args = TrainingArguments(output_dir=model_dir,\n",
    "                                  evaluation_strategy=\"steps\",\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  num_train_epochs=num_epochs,\n",
    "                                  logging_steps=4000,\n",
    "                                  weight_decay=0.01,\n",
    "                                  warmup_steps=warmup_steps)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0ce03480-3aaa-48ea-a0c6-a177b8d8e34f",
   "metadata": {},
   "source": [
    "# 完整的超参数配置\n",
    "print(training_args)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7ebd3365-d359-4ab4-a300-4717590cc240",
   "metadata": {},
   "source": [
    "### 训练过程中的指标评估（Evaluate)\n",
    "\n",
    "**[Hugging Face Evaluate 库](https://huggingface.co/docs/evaluate/index)** 支持使用一行代码，获得数十种不同领域（自然语言处理、计算机视觉、强化学习等）的评估方法。 当前支持 **完整评估指标：https://huggingface.co/evaluate-metric**\n",
    "\n",
    "训练器（Trainer）在训练过程中不会自动评估模型性能。因此，我们需要向训练器传递一个函数来计算和报告指标。 \n",
    "\n",
    "Evaluate库提供了一个简单的准确率函数，您可以使用`evaluate.load`函数加载"
   ]
  },
  {
   "cell_type": "code",
   "id": "2a8ef138-5bf2-41e5-8c68-df8e11f4e98f",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "70d406c0-56d0-4a54-9c6c-e126ab7f5254",
   "metadata": {},
   "source": [
    "\n",
    "接着，调用 `compute` 函数来计算预测的准确率。\n",
    "\n",
    "在将预测传递给 compute 函数之前，我们需要将 logits 转换为预测值（**所有Transformers 模型都返回 logits**）。"
   ]
  },
  {
   "cell_type": "code",
   "id": "f46d2e59-1ebf-43d2-bc86-6b57a4d24d19",
   "metadata": {},
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d47d6981-e444-4c0f-a7cb-dd7f2ba8df12",
   "metadata": {},
   "source": [
    "## 开始训练\n",
    "\n",
    "### 实例化训练器（Trainer）\n",
    "\n",
    "`kernel version` 版本问题：暂不影响本示例代码运行"
   ]
  },
  {
   "cell_type": "code",
   "id": "ca1d12ac-89dc-4c30-8282-f859724c0062",
   "metadata": {},
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "accfe921-471d-481a-96da-c491cdebad0c",
   "metadata": {},
   "source": [
    "trainer.train()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6d581099-37a4-4470-b051-1ada38554089",
   "metadata": {},
   "source": [
    "small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=64)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ffb47eab-1370-491e-8a84-6d5347a350b2",
   "metadata": {},
   "source": [
    "trainer.evaluate(small_test_dataset)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "27a55686-7c43-4ab8-a5cd-0e77f14c7c52",
   "metadata": {},
   "source": [
    "### 保存模型和训练状态\n",
    "\n",
    "- 使用 `trainer.save_model` 方法保存模型，后续可以通过 from_pretrained() 方法重新加载\n",
    "- 使用 `trainer.save_state` 方法保存训练状态"
   ]
  },
  {
   "cell_type": "code",
   "id": "ad0cbc14-9ef7-450f-a1a3-4f92b6486f41",
   "metadata": {},
   "source": [
    "trainer.save_model(model_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "badf5868-2847-439d-a73e-42d1cca67b5e",
   "metadata": {},
   "source": [
    "trainer.save_state()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
