{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T03:00:12.757726Z",
     "start_time": "2024-09-04T03:00:12.080453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "8211dcdebff544a7",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "\n",
    "        assert (self.head_dim * heads == embed_size), \"Embed size needs to be divisible by heads\"\n",
    "\n",
    "        self.W_V = nn. Linear(self.embed_size, self.embed_size, bias=False)\n",
    "        self.W_K = nn.Linear(self.embed_size, self.embed_size, bias=False)\n",
    "        self.W_Q = nn.Linear(self.embed_size, self.embed_size, bias=False)\n",
    "        self.fc_out = nn.Linear(heads * self.head_dim, embed_size)\n",
    "\n",
    "    def forward(self, values, keys, query, mask):\n",
    "        N = query.shape[0]\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
    "\n",
    "        # Split embedding into self.heads pieces\n",
    "        values = self.W_V(values).reshape(N, value_len, self.heads, self.head_dim)\n",
    "        keys = self.W_K(keys).reshape(N, key_len, self.heads, self.head_dim)\n",
    "        queries = self.W_Q(query).reshape(N, query_len, self.heads, self.head_dim)\n",
    "\n",
    "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
    "\n",
    "        attention = torch.softmax(energy / (self.embed_size ** (1/2)), dim=3)\n",
    "\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(\n",
    "            N, query_len, self.heads * self.head_dim\n",
    "        )\n",
    "        out = self.fc_out(out)\n",
    "        return out, attention\n",
    "\n",
    "# 示例使用\n",
    "embed_size = 256\n",
    "heads = 8\n",
    "seq_length = 10\n",
    "batch_size = 1\n",
    "\n",
    "mha = MultiHeadAttention(embed_size, heads)\n",
    "x = torch.randn(batch_size, seq_length, embed_size)\n",
    "mask = torch.ones(batch_size, 1, seq_length, seq_length)\n",
    "\n",
    "output, attention = mha(x, x, x, mask)\n",
    "\n",
    "# 可视化不同头的注意力分布\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i in range(heads):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.imshow(attention[0, i].detach().numpy(), cmap='viridis')\n",
    "    plt.title(f'Head {i+1}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T04:33:01.041881Z",
     "start_time": "2024-09-04T04:33:01.039719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 1\n",
    "seq_length = 5\n",
    "embed_size = 6\n",
    "heads = 2"
   ],
   "id": "92b1efb44983c91f",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "linear = nn.Linear(5, 4)\n",
    "#linear.weight.data = torch.randn(4, 5)\n",
    "print(linear.weight.shape)\n",
    "print(linear.weight)\n",
    "\n",
    "x = torch.tensor([1.0, 2.0, -1.0, 0.0, 3.0])\n",
    "print(x.shape)\n",
    "print(linear(x))"
   ],
   "id": "3a1f9b5a45768c0f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T04:33:01.554623Z",
     "start_time": "2024-09-04T04:33:01.551702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.randn(batch_size, seq_length, embed_size)\n",
    "print(x.shape[0])\n",
    "print(x.shape[1])\n",
    "print(x.shape[2])"
   ],
   "id": "10305c8467719747",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T04:33:04.831907Z",
     "start_time": "2024-09-04T04:33:04.828907Z"
    }
   },
   "cell_type": "code",
   "source": "torch.ones(batch_size, 1, seq_length, seq_length)",
   "id": "b1afc8df644137b0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T04:33:08.109083Z",
     "start_time": "2024-09-04T04:33:08.105681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "W_V = nn.Linear(embed_size, embed_size, bias=False)\n",
    "v = W_V(x)\n",
    "print(v)\n",
    "print(v.shape)\n",
    "v = v.reshape(x.shape[0], x.shape[1], heads, embed_size // heads)\n",
    "print(v)\n",
    "print(v.shape)"
   ],
   "id": "a9fa7c23a1baf61c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4418,  0.2320, -0.6752, -0.3111,  0.5736, -0.5544],\n",
      "         [ 0.5012,  0.5117, -1.6920, -0.9251, -0.2557, -1.0512],\n",
      "         [ 0.8153, -0.3434, -0.4991, -0.2057, -0.0357, -0.5482],\n",
      "         [-0.6561,  0.2849,  0.7725,  0.2777,  0.5643,  0.3041],\n",
      "         [-0.5946, -0.1228,  0.6577,  0.1047, -0.6076,  0.8863]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 5, 6])\n",
      "tensor([[[[ 0.4418,  0.2320, -0.6752],\n",
      "          [-0.3111,  0.5736, -0.5544]],\n",
      "\n",
      "         [[ 0.5012,  0.5117, -1.6920],\n",
      "          [-0.9251, -0.2557, -1.0512]],\n",
      "\n",
      "         [[ 0.8153, -0.3434, -0.4991],\n",
      "          [-0.2057, -0.0357, -0.5482]],\n",
      "\n",
      "         [[-0.6561,  0.2849,  0.7725],\n",
      "          [ 0.2777,  0.5643,  0.3041]],\n",
      "\n",
      "         [[-0.5946, -0.1228,  0.6577],\n",
      "          [ 0.1047, -0.6076,  0.8863]]]], grad_fn=<ViewBackward0>)\n",
      "torch.Size([1, 5, 2, 3])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T05:26:08.074965Z",
     "start_time": "2024-09-04T05:26:08.071928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.matmul(v[0,0,0], v[0,0,0])\n",
    "torch.dot(v[0,0,0], v[0,0,0])"
   ],
   "id": "2da1477b1cf3280b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7050, grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T06:21:56.647773Z",
     "start_time": "2024-09-04T06:21:56.644933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "energy = torch.einsum(\"nqhd,nkhd->nhqk\", [v, v])\n",
    "print(energy)\n",
    "print(energy.shape)"
   ],
   "id": "16f7d159b1a658f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.7050,  1.4826,  0.6176, -0.7454, -0.7353],\n",
      "          [ 1.4826,  3.3759,  1.0774, -1.4901, -1.4737],\n",
      "          [ 0.6176,  1.0774,  1.0317, -1.0183, -0.7709],\n",
      "          [-0.7454, -1.4901, -1.0183,  1.1084,  0.8632],\n",
      "          [-0.7353, -1.4737, -0.7709,  0.8632,  0.8012]],\n",
      "\n",
      "         [[ 0.7332,  0.7239,  0.3474,  0.0687, -0.8725],\n",
      "          [ 0.7239,  2.0262,  0.7756, -0.7209, -0.8732],\n",
      "          [ 0.3474,  0.7756,  0.3441, -0.2440, -0.4857],\n",
      "          [ 0.0687, -0.7209, -0.2440,  0.4880, -0.0442],\n",
      "          [-0.8725, -0.8732, -0.4857, -0.0442,  1.1657]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "torch.Size([1, 2, 5, 5])\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T06:21:53.985220Z",
     "start_time": "2024-09-04T06:21:53.982295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "attention = torch.softmax(energy / (embed_size ** (1/2)), dim=3)\n",
    "print(attention)\n",
    "print(attention.shape)"
   ],
   "id": "d94998dbee3e95b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.2249, 0.3089, 0.2170, 0.1244, 0.1249],\n",
      "          [0.2169, 0.4699, 0.1838, 0.0645, 0.0649],\n",
      "          [0.2237, 0.2699, 0.2649, 0.1147, 0.1269],\n",
      "          [0.1494, 0.1103, 0.1337, 0.3185, 0.2882],\n",
      "          [0.1534, 0.1135, 0.1512, 0.2946, 0.2873]],\n",
      "\n",
      "         [[0.2420, 0.2411, 0.2067, 0.1845, 0.1256],\n",
      "          [0.2084, 0.3546, 0.2128, 0.1155, 0.1086],\n",
      "          [0.2134, 0.2541, 0.2131, 0.1676, 0.1518],\n",
      "          [0.2107, 0.1526, 0.1854, 0.2500, 0.2012],\n",
      "          [0.1455, 0.1455, 0.1704, 0.2041, 0.3345]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 2, 5, 5])\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T07:01:50.919992Z",
     "start_time": "2024-09-04T07:01:50.916746Z"
    }
   },
   "cell_type": "code",
   "source": "torch.einsum(\"nhql,nlhd->nqhd\", [attention, v])",
   "id": "60522bcf3ee01294",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2752,  0.1558, -0.6045],\n",
       "          [-0.2764,  0.0975, -0.3335]],\n",
       "\n",
       "         [[ 0.4003,  0.2380, -0.9408],\n",
       "          [-0.3932,  0.0205, -0.4737]],\n",
       "\n",
       "         [[ 0.2993,  0.1161, -0.5678],\n",
       "          [-0.2828,  0.0521, -0.3167]],\n",
       "\n",
       "         [[-0.1501,  0.1005,  0.0814],\n",
       "          [-0.1544,  0.0940, -0.1246]],\n",
       "\n",
       "         [[-0.1162,  0.0904,  0.0455],\n",
       "          [-0.1232, -0.0479,  0.0314]]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "705aac74454e3645"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
