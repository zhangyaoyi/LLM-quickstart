{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        # Create a long enough 'P'\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        \n",
    "        # Register buffer (not a parameter of the model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "\n",
    "# Example usage:\n",
    "# d_model = 512  # Dimension of the model\n",
    "# max_seq_length = 100  # Maximum sequence length\n",
    "# pos_encoder = PositionalEncoding(d_model, max_seq_length)\n",
    "# \n",
    "# # Assuming 'x' is your input tensor of shape (seq_len, batch_size, d_model)\n",
    "# x = torch.randn(max_seq_length, batch_size, d_model)\n",
    "# x = pos_encoder(x)\n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab_size, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)\n",
    "\n",
    "# Example usage:\n",
    "# vocab_size = 10000  # Size of the vocabulary\n",
    "# d_model = 512  # Dimension of the model\n",
    "# embedding = Embeddings(vocab_size, d_model)\n",
    "# x = torch.LongTensor([[1, 2, 3, 4], [5, 6, 7, 8]])  # Example input\n",
    "# output = embedding(x)\n",
    "# print(output.shape)  # Should be (batch_size, sequence_length, d_model)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, max_seq_length, pos"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
